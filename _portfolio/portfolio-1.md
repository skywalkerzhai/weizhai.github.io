---
title: "Research Theme 1——Artificial Intelligence, Big Data, and Climate Resilience"
excerpt: "<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/AI_resilience.jpg' width='600'>"
collection: portfolio
---
* Paper 1: [Damage assessment using Google Street View: Evidence from Hurricane Michael in Mexico Beach, Florida](https://doi.org/10.1016/j.apgeog.2020.102252)

  * Assessing damage on the ground is a challenging task for humanitarian organizations and disaster managers due to the limited availability of data and methods for processing. As the most commonly adopted data source, remote sensing imagery can only reflect the damage situation on top of a building and fails to present the damage level from the perspective of the human eye. Recently, an increasing number of Google Street View (GSV) images provide the chance to understand the human's perception of damage on the ground. However, to automatically and quantitatively apply GSV images in damage assessment, two research questions need to be answered: (1) Can deep learning be successfully applied to automate the process of evaluating postdisaster damage using GSV images? (2) Does damage assessment using GSV images provide a different insight, compared with existing approaches, such as remote sensing imagery?
  * **Keywords: Damage assessment; Google street view; Deep learning**\
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/michael_path.jpg' width='600'>\
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/michael_damage.jpg' width='600'>\
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/DL_damage.jpg' width='600'>\
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/damag_GSV.jpg' width='600'>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/nGs48HGnRN4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
&nbsp;
<iframe width="800" height="315" src="https://yuh2k.github.io/Twitter-Social-Network-Analysis-of-Hurricane-Sandy-/Correction%20Network/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<hr style="border:2px solid grey">
&nbsp;
&nbsp;

* Paper 2: [Examine the effects of neighborhood equity on disaster situational awareness: Harness machine learning and geotagged Twitter data](https://doi.org/10.1016/j.ijdrr.2020.101611)
  * A disaster-resilient city should address social inequity in all its forms. Complete, accurate, and up-to-the-minute situational awareness (SA) can help disaster relief organizations stabilize the dangers and prevent further losses in poor and ethnic minority neighborhoods. However, the lapse of months or years of survey data could lead to biases since retrospective studies are affected by the emotional status at the time of the survey. To address this, we aim to examine the effects of neighborhood equity on SA in a hurricane event using geotagged Twitter data. We adopted the sentiment analysis, convolutional neural network (CNN) model and latent Dirichlet allocation (LDA) model to reflect SA in Hurricane Florence. The multinomial logit regression model reveals that the tweet originated from a poor neighborhood has a higher probability of being more negative, compared to being neutral. Also, we surprisingly found that the sentiment of a tweet in a black neighborhood could be less likely to be negative. Another novel finding is that black neighborhoods could discuss the hurricane with a positive attitude while poor neighborhoods are more concerned about the work during the hurricane. This study shows that, by incorporating with aggregated sociodemographic data, geotagged Twitter data can also be used to understand disaster SA from the perspective of social equity.

  * **Keywords: Neighborhood equity; Situational awareness; Machine learning; Twitter**\
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/Hurricane_Florence_rainfall.png' width='600'> \
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/hurricane_tweet.jpg' width='600'> \
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/twitter_framework.jpg' width='600'> \
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/twitter_DL.jpg' width='600'>
<hr style="border:2px solid grey">
&nbsp;
&nbsp;


* AI for Earth Grant: [Evaluation and Prediction of American’s Mobility under Extreme Weather Events using Artificial Intelligence](https://colab.research.google.com/drive/1GnAoSXBKlQOTZHpGZJtpHnOQzFolN2U1?usp=sharing)

  * This project addresses the challenge of evaluation and prediction of human mobility under extreme weather events (EWEs), which are impacted by the changing climate. Artificial Intelligence can give people more accurate predictions to help reduce the potential impacts of EWEs on human mobility, which plays a critical role in developing evacuation strategies, saving lives, reducing economic loss, planning effective humanitarian relief, and so on. Taking advantage of AI techniques, our  project aims to predict human mobility under EWEs across America’s big cities. 
  * **Keywords: Extreme weather; AI; Human mobility**\
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/extreme_weather.jpg' width='600'> \
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/output_20_0.png' width='600'> \
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/output_21_0.png' width='600'> \
<br/><img src='https://skywalkerzhai.github.io/weizhai.github.io/images/output_53_0.png' width='600'> 
